@*<h2>Speech to Text (Microphone)</h2>

    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>

    <p id="status"></p>
    <div id="result" style="margin-top: 20px; font-weight: bold;"></div>*@

@{ ViewData["Title"] = "Speech to Text Recorder"; }

<style>
    /* Base styles */
    html {
        font-size: 14px;
        position: relative;
        min-height: 100%;
    }

    @@media (min-width: 768px) {
        html {
            font-size: 16px;
        }
    }

    body {
        margin-bottom: 60px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }

    /* Footer */
    .footer {
        position: absolute;
        bottom: 0;
        width: 100%;
        white-space: nowrap;
        line-height: 60px;
    }

    /* Speech recorder styles */
    .speech-recorder {
        max-width: 800px;
        margin: 0 auto;
    }

    .recorder-visualizer {
        width: 100%;
        height: 60px;
        background-color: #f8f9fa;
        border-radius: 4px;
        margin-bottom: 1rem;
    }

    .recorder-controls {
        display: flex;
        justify-content: center;
        gap: 10px;
    }

    #result {
        min-height: 100px;
        white-space: pre-wrap;
        font-size: 1.1rem;
    }

    /* Status indicators */
    .recording-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        background-color: #dc3545;
        margin-right: 5px;
        animation: pulse 1.5s infinite;
    }

    @@keyframes pulse {
        0% {
            opacity: 1;
        }

        50% {
            opacity: 0.5;
        }

        100% {
            opacity: 1;
        }
    }
</style>

<div class="speech-recorder">
    <h2>Speech to Text Recorder</h2>

    <div class="recorder-status mt-4">
        <div class="card">
            <div class="card-body">
                <h5 class="card-title">Recorder Status</h5>
                <p id="status" class="card-text">Ready to record</p>

                <div class="d-flex justify-content-center mb-3">
                    <div id="visualizer" class="recorder-visualizer"></div>
                </div>

                <div class="recorder-controls">
                    <button id="startBtn" class="btn btn-primary me-2">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-mic-fill" viewBox="0 0 16 16">
                            <path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z" />
                            <path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z" />
                        </svg>
                        Start Recording
                    </button>
                    <button id="stopBtn" class="btn btn-danger" disabled>
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-stop-fill" viewBox="0 0 16 16">
                            <path d="M5 3.5h6A1.5 1.5 0 0 1 12.5 5v6a1.5 1.5 0 0 1-1.5 1.5H5A1.5 1.5 0 0 1 3.5 11V5A1.5 1.5 0 0 1 5 3.5z" />
                        </svg>
                        Stop Recording
                    </button>
                </div>

                <div id="audio-playback" class="mt-3 d-none">
                    <h6>Preview Recording</h6>
                    <audio id="audio-preview" controls class="w-100"></audio>
                </div>
            </div>
        </div>
    </div>

    <div class="transcription-result mt-4">
        <div class="card">
            <div class="card-body">
                <h5 class="card-title">Transcription Result</h5>
                <div id="result-container">
                    <p id="result-placeholder" class="text-muted">Your transcription will appear here after recording</p>
                    <div id="result" class="p-3 bg-light rounded d-none"></div>
                </div>
            </div>
        </div>
    </div>
</div>




@section Scripts {
    @*<script>
            let mediaRecorder;
            let audioChunks = [];

            $(document).ready(function() {
                $("#startBtn").on("click", async function() {
                    $("#result").text("");
                    $("#status").text("Recording...");

                    try {
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        mediaRecorder = new MediaRecorder(stream);

                        audioChunks = [];

                        mediaRecorder.ondataavailable = event => {
                            if (event.data.size > 0) {
                                audioChunks.push(event.data);
                            }
                        };

                        mediaRecorder.onstop = async () => {
                            $("#status").text("Sending for transcription...");

                            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                            const blobUrl = URL.createObjectURL(audioBlob);
                            const formData = new FormData();
                            formData.append("audioFile", audioBlob, "recording.wav");
                            for (let [key, value] of formData.entries()) {
                                console.log(key, value);
                            }

                            try {
                                const response = await fetch('@Url.Action("STT", "Voice")', {
                                    method: 'POST',
                                    body: formData
                                });

                                const data = await response.json();

                                if (!response.ok) {
                                    throw new Error(data.error || "Unknown error");
                                }

                                $("#result").text("Transcription: " + data.transcription);
                            } catch (err) {
                                $("#result").text("Error: " + err.message);
                            } finally {
                                $("#status").text("");
                            }
                        };

                        mediaRecorder.start();
                        $("#startBtn").prop("disabled", true);
                        $("#stopBtn").prop("disabled", false);

                        setTimeout(() => {
                            mediaRecorder.stop();
                        }, 5000);
                    } catch (error) {
                        $("#result").text("Error starting recording: " + error.message); //show the error to user
                        $("#status").text("");
                        $("#startBtn").prop("disabled", false); // re-enable start button
                        $("#stopBtn").prop("disabled", true);
                        console.error("Error starting recording", error); //log the error.
                    }

                });

                $("#stopBtn").on("click", function() {
                    mediaRecorder.stop();
                    $("#startBtn").prop("disabled", false);
                    $("#stopBtn").prop("disabled", true);
                });
        </script>
            });*@

    <script>
        (function () {
            // Global variables
            let mediaRecorder;
            let audioChunks = [];
            let audioStream;
            let audioContext;
            let analyser;
            let visualizerCanvas;
            let canvasContext;
            let animationId;

            // DOM elements
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const statusEl = document.getElementById('status');
            const resultEl = document.getElementById('result');
            const resultPlaceholder = document.getElementById('result-placeholder');
            const audioPlayback = document.getElementById('audio-playback');
            const audioPreview = document.getElementById('audio-preview');
            const visualizer = document.getElementById('visualizer');

            // Set up visualizer canvas
            function setupVisualizer() {
                visualizerCanvas = document.createElement('canvas');
                visualizerCanvas.width = visualizer.clientWidth;
                visualizerCanvas.height = 60;
                visualizer.appendChild(visualizerCanvas);
                canvasContext = visualizerCanvas.getContext('2d');
            }

            // Initialize event listeners
            function init() {
                setupVisualizer();

                startBtn.addEventListener('click', startRecording);
                stopBtn.addEventListener('click', stopRecording);

                // Check if browser supports audio recording
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    statusEl.textContent = 'Your browser does not support audio recording.';
                    startBtn.disabled = true;
                    return;
                }
            }

            // Draw the audio visualizer
            function drawVisualizer() {
                if (!analyser) return;

                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                analyser.getByteTimeDomainData(dataArray);

                canvasContext.clearRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
                canvasContext.lineWidth = 2;
                canvasContext.strokeStyle = '#007bff';
                canvasContext.beginPath();

                const sliceWidth = visualizerCanvas.width / bufferLength;
                let x = 0;

                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i] / 128.0;
                    const y = v * visualizerCanvas.height / 2;

                    if (i === 0) {
                        canvasContext.moveTo(x, y);
                    } else {
                        canvasContext.lineTo(x, y);
                    }

                    x += sliceWidth;
                }

                canvasContext.lineTo(visualizerCanvas.width, visualizerCanvas.height / 2);
                canvasContext.stroke();
                animationId = requestAnimationFrame(drawVisualizer);
            }

            // Start audio recording
            async function startRecording() {
                try {
                    // Reset previous recording
                    audioChunks = [];
                    resultEl.textContent = '';
                    resultEl.classList.add('d-none');
                    resultPlaceholder.classList.remove('d-none');
                    audioPlayback.classList.add('d-none');

                    // Update UI
                    statusEl.textContent = 'Requesting microphone access...';
                    startBtn.disabled = true;

                    // Get audio stream
                    audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                    // Set up audio context and analyser for visualization
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(audioStream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 2048;
                    source.connect(analyser);

                    // Start visualization
                    drawVisualizer();

                    // Create and configure MediaRecorder
                    // Check for supported MIME types
                    const mimeTypes = [
                        'audio/webm;codecs=opus',
                        'audio/webm',
                        'audio/ogg;codecs=opus',
                        'audio/mp4'
                    ];

                    let mimeType = '';
                    for (let type of mimeTypes) {
                        if (MediaRecorder.isTypeSupported(type)) {
                            mimeType = type;
                            console.log('Using MIME type:', mimeType);
                            break;
                        }
                    }

                    if (!mimeType) {
                        console.warn('None of the preferred MIME types are supported, using default');
                    }

                    const recorderOptions = mimeType ? { mimeType } : {};
                    mediaRecorder = new MediaRecorder(audioStream, recorderOptions);

                    mediaRecorder.addEventListener('dataavailable', event => {
                        if (event.data.size > 0) {
                            console.log(`Received audio chunk: size=${event.data.size} type=${event.data.type}`);
                            audioChunks.push(event.data);
                        }
                    });

                    mediaRecorder.addEventListener('start', () => {
                        statusEl.textContent = 'Recording in progress...';
                        stopBtn.disabled = false;
                    });

                    mediaRecorder.addEventListener('stop', sendAudioToServer);

                    // Start recording - use a time slice to get data during recording
                    // instead of only at the end, which helps with larger recordings
                    console.log('Starting MediaRecorder with options:', recorderOptions);
                    mediaRecorder.start(1000); // Get data every second
                } catch (error) {
                    console.error('Error starting recording:', error);
                    statusEl.textContent = `Error: ${error.message}`;
                    startBtn.disabled = false;
                }
            }

            // Stop audio recording
            function stopRecording() {
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    statusEl.textContent = 'Stopping recording...';
                    mediaRecorder.stop();
                    stopBtn.disabled = true;

                    // Stop the audio tracks
                    if (audioStream) {
                        audioStream.getTracks().forEach(track => track.stop());
                    }

                    // Stop the visualizer
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                }
            }

            //convert type to wav
            async function convertBlobToWav(blob) {
                const arrayBuffer = await blob.arrayBuffer();
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

                const numOfChan = audioBuffer.numberOfChannels,
                    length = audioBuffer.length * numOfChan * 2 + 44,
                    buffer = new ArrayBuffer(length),
                    view = new DataView(buffer),
                    channels = [],
                    sampleRate = audioBuffer.sampleRate;

                let offset = 0;
                function setUint16(data) { view.setUint16(offset, data, true); offset += 2; }
                function setUint32(data) { view.setUint32(offset, data, true); offset += 4; }

                // Write WAV header
                setUint32(0x46464952); // "RIFF"
                setUint32(length - 8); // file length - 8
                setUint32(0x45564157); // "WAVE"

                setUint32(0x20746d66); // "fmt " chunk
                setUint32(16); // length = 16
                setUint16(1); // PCM (uncompressed)
                setUint16(numOfChan);
                setUint32(sampleRate);
                setUint32(sampleRate * 2 * numOfChan); // byte rate
                setUint16(numOfChan * 2); // block align
                setUint16(16); // bits per sample

                setUint32(0x61746164); // "data" chunk
                setUint32(length - offset - 4); // data length

                // Write interleaved PCM samples
                for (let i = 0; i < numOfChan; i++) {
                    channels.push(audioBuffer.getChannelData(i));
                }

                for (let i = 0; i < audioBuffer.length; i++) {
                    for (let ch = 0; ch < numOfChan; ch++) {
                        let sample = Math.max(-1, Math.min(1, channels[ch][i]));
                        sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                        view.setInt16(offset, sample, true);
                        offset += 2;
                    }
                }

                return new Blob([buffer], { type: 'audio/wav' });
            }


            // Send recorded audio to the server for transcription
            async function sendAudioToServer() {
                try {
                    statusEl.textContent = 'Processing audio...';

                    const blobMimeType = mediaRecorder ? mediaRecorder.mimeType || 'audio/webm' : 'audio/webm';
                    console.log('Creating blob with MIME type:', blobMimeType);

                    console.log(`Number of audio chunks: ${audioChunks.length}`);
                    audioChunks.forEach((chunk, i) => {
                        console.log(`Chunk ${i}: size=${chunk.size}, type=${chunk.type}`);
                    });

                    if (audioChunks.length === 0) {
                        throw new Error("No audio data was captured during recording");
                    }

                    const rawBlob = new Blob(audioChunks, { type: blobMimeType });
                    const audioBlob = await convertBlobToWav(rawBlob);
                    const filename = `recording_${Date.now()}.wav`;


                    console.log(`Final blob: size=${audioBlob.size}, type=${audioBlob.type}`);

                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPreview.src = audioUrl;
                    audioPlayback.classList.remove('d-none');

                    // Create FormData for the server request (only once)
                    var formData = new FormData();

                    let fileExtension = '.webm';
                    if (blobMimeType.includes('webm')) {
                        fileExtension = '.webm';
                    } else if (blobMimeType.includes('ogg')) {
                        fileExtension = '.ogg';
                    } else if (blobMimeType.includes('mp4')) {
                        fileExtension = '.mp4';
                    } else if (blobMimeType.includes('mp3')) {
                        fileExtension = '.mp3';
                    }

                    //const filename = `recording_${Date.now()}${fileExtension}`;
                    console.log('Using filename:', filename);

                    formData.append('audioFile', audioBlob, filename);

                    const tokenElement = document.querySelector('input[name="__RequestVerificationToken"]');
                    if (tokenElement) {
                        console.log('Adding antiforgery token to request');
                        formData.append('__RequestVerificationToken', tokenElement.value);
                    } else {
                        console.warn('Antiforgery token not found in the page');
                    }

                    console.log('FormData entries:');
                    for (let pair of formData.entries()) {
                        console.log(pair[0], pair[1], 'filename:', pair[1].name, 'type:', pair[1].type, 'size:', pair[1].size);
                    }

                    statusEl.textContent = 'Sending to server for transcription...';
                    console.log('Sending request to /Voice/STTs');

                    try {
                        const response = await fetch('/Voice/STTs', {
                            method: 'POST',
                            body: formData // Use the FormData created earlier
                        });

                        console.log('Response status:', response.status);

                        if (!response.ok) {
                            const errorText = await response.text();
                            console.error('Error response text:', errorText);
                            throw new Error(`Server returned ${response.status}`);
                        }

                        const data = await response.json();
                        console.log('Response data:', data);

                        resultPlaceholder.classList.add('d-none');
                        resultEl.classList.remove('d-none');
                        resultEl.textContent = data.transcription || 'No transcription returned';

                        statusEl.textContent = 'Recording complete. Ready to record again.';
                        startBtn.disabled = false;
                    } catch (error) {
                        console.error('Error sending audio:', error);
                        statusEl.textContent = `Error: ${error.message}`;
                        startBtn.disabled = false;

                        resultPlaceholder.classList.add('d-none');
                        resultEl.classList.remove('d-none');
                        resultEl.innerHTML = `<div class="text-danger">Error: ${error.message}</div>`;
                    }

                } catch (error) {
                    console.error('Error processing audio:', error);
                    statusEl.textContent = `Error: ${error.message}`;
                    startBtn.disabled = false;

                    resultPlaceholder.classList.add('d-none');
                    resultEl.classList.remove('d-none');
                    resultEl.innerHTML = `<div class="text-danger">Error: ${error.message}</div>`;
                }
            }

            // Initialize when DOM is loaded
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', init);
            } else {
                init();
            }
        })();


    </script>
}



